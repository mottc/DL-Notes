{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 算法性能度量标准(metrics)\n",
    "---\n",
    "\n",
    "在分类算法或者目标检测中，都需要一个指标来度量算法的好坏。本文主要简介在分类算法和目标检测算法中常用的度量方法。\n",
    "\n",
    "### 1. 实际检测中的四种情况\n",
    "+ TN=True Negative 真负，将负类预测为负类的数量\n",
    "+ FP=False Positive 假正，将负类预测为正类的数量，可以称为误报率\n",
    "+ FN=False Negative 假负，将正类预测为负类的数量，可以称为漏报率\n",
    "+ TP=True Positve 真正，将正类预测为正类的数量\n",
    "\n",
    "### 2. 准确率（accuracy）\n",
    "accuracy = (TP + TN)/(TP + FP + FN + TN)\n",
    "\n",
    "有100个sample，99个反例，只有1个正例。如果模型不分青红皂白对任意一个sample都预测是反例，那么模型的accuracy是 分类正确的个数／总个数 = 99/100 = 99%\n",
    "### 3. 精确率（precision）与召回率（recall）\n",
    "precision=TP/(TP+FP)\n",
    "\n",
    "recall=TP/(TP+FN)\n",
    "![avatar](./images/precision_and_recall.jpg)\n",
    "\n",
    "### 4. F1值（F1-score）\n",
    "F1 score 为精确率与召回率的调和均值\n",
    "\n",
    "2/F1 = 1/precision + 1/recall\n",
    "\n",
    "F1 score = 2TP/(2TP+FP+FN)\n",
    "\n",
    "### 5. ROC\n",
    "对于正负例的界定，通常会设一个阈值，大于阈值的为正类，小于阈值为负类。如果减小这个阀值，更多的样本会被识别为正类，提高正类的识别率，但同时也会使得更多的负类被错误识别为正类。为了直观表示这一现象，引入ROC，ROC曲线可以用于评价一个分类器好坏。\n",
    "\n",
    "ROC关注两个指标：\n",
    "\n",
    "- 纵坐标：True Positive Rate: TPR = TP / (TP+FN) → 将正例分对的概率（所有正样本中，被判为正样本）\n",
    "- 横坐标：Fales Positive Rate: FPR = FP / (FP+TN) → 将负例错分为正例的概率（所有负样本中，被误判为正样本）\n",
    "\n",
    "![ROC](./images/ROC.png)\n",
    "\n",
    "首先，FPR=0, TPR=1的那个点，可以推测FN=0, FP=0:一个错误都没有，所以是Perfect Classification。\n",
    "\n",
    "中间这条红线，我们观察TPR=FPR，所以TP(FP+TN)=FP(TP+FN)，所以TP/FN = FP/TN：换言之，无论样本是真是假，我们将它们判为“真”或“假”的概率都相当，或者说，我们的猜测是完全随机的。\n",
    "\n",
    "在红线上方，偏Perfect Classification的区域，我们认为是优于随机猜测。因为，在红线上的任意一点垂直向上的点，都有同样的FPR，但总是得到更高的TPR：在错误不变的情况下，我们的Recall变高了。\n",
    "\n",
    "反之，在红线下方的点，都认为是劣于随机猜测。\n",
    "\n",
    "对于一个特定的分类器和测试数据集，显然只能得到一个分类结果，即一组FPR和TPR结果，而要得到一个曲线，实际上需要一系列FPR和TPR的值。ROC曲线的定义:\n",
    "\n",
    "> In signal detection theory, a receiver operating characteristic (ROC), or simply ROC curve, is a graphical plot which illustrates the performance of a binary classifier system as its discrimination threshold is varied.\n",
    "\n",
    "实例：\n",
    "\n",
    "![ROC](./images/ROC1.webp)\n",
    "![ROC](./images/ROC2.webp)\n",
    "\n",
    "### 6. AUC\n",
    "\n",
    "AUC (Area Under Curve) 被定义为ROC曲线下的面积，显然这个面积的数值不会大于1。又由于ROC曲线一般都处于y=x这条直线的上方，所以AUC的取值范围一般在0.5和1之间。使用AUC值作为评价标准是因为很多时候ROC曲线并不能清晰的说明哪个分类器的效果更好，而作为一个数值，对应AUC更大的分类器效果更好。\n",
    "\n",
    "从AUC判断分类器（预测模型）优劣的标准：\n",
    "\n",
    "- AUC = 1，是完美分类器，采用这个预测模型时，存在至少一个阈值能得出完美预测。绝大多数预测的场合，不存在完美分类器。\n",
    "- 0.5 < AUC < 1，优于随机猜测。这个分类器（模型）妥善设定阈值的话，能有预测价值。\n",
    "- AUC = 0.5，跟随机猜测一样（例：丢铜板），模型没有预测价值。\n",
    "- AUC < 0.5，比随机猜测还差；但只要总是反预测而行，就优于随机猜测。\n",
    "\n",
    "---\n",
    "---\n",
    "\n",
    "### 7.目标识别中的一些概念\n",
    "\n",
    "![IOU](./images/IOU.png)\n",
    "\n",
    "- True Positive (TP): 正检： IOU ≥ threshold\n",
    "- False Positive (FP): 误检： IOU < threshold或者检测一个目标多余的框\n",
    "- False Negative (FN):漏检\n",
    "\n",
    "\n",
    "precision=TP/(TP+FP)\n",
    "\n",
    "recall=TP/(TP+FN)\n",
    "\n",
    "### 8. PRC(Precision  Recall curve)\n",
    "\n",
    "- 纵坐标：precision\n",
    "- 横坐标：recall\n",
    "\n",
    "若要recall大，可以框出无限个框，总会把所有目标包含，但此时precision极低；\n",
    "\n",
    "若要precision大，只框出一个概率最大的，但此时recall极低。\n",
    "\n",
    "![PRC](./images/PRC.png)\n",
    "![PRC](./images/PRC1.png)\n",
    "![PRC](./images/PRC2.png)\n",
    "\n",
    "### 9. AP(Average Precision)\n",
    "\n",
    "PRC是一条曲线，不好比较优劣。需要一个数值来描述PRC，那就是AP。\n",
    "\n",
    "- 11-point interpolation\n",
    "![11](./images/11-pointInterpolation.png)\n",
    "![11](./images/11.jpg)\n",
    "\n",
    "- all points interpolation\n",
    "![all](./images/interpolated_precision_v2.png)\n",
    "![all](./images/interpolated_precision-AUC_v2.png)\n",
    "![all](./images/all.jpg)\n",
    "\n",
    "\n",
    "# 10. mAP\n",
    "多个AP求均值\n",
    "\n",
    "\n",
    "### 参考资料\n",
    "1. [多标签图像分类任务的评价方法-mAP](http://blog.sina.com.cn/s/blog_9db078090102whzw.html)\n",
    "2. [精确率、召回率、F1 值、ROC、AUC 各自的优缺点是什么？- 邓小乔的回答 - 知乎](https://www.zhihu.com/question/30643044/answer/224360465)\n",
    "3. [深度学习分类任务评价指标](https://blog.csdn.net/zong596568821xp/article/details/80797695)\n",
    "4. [Object-Detection-Metrics](https://github.com/rafaelpadilla/Object-Detection-Metrics)\n",
    "5. [Measuring Object Detection models - mAP - What is Mean Average Precision?](http://tarangshah.com/blog/2018-01-27/what-is-map-understanding-the-statistic-of-choice-for-comparing-object-detection-models/)\n",
    "6. [机器学习之分类性能度量指标 : ROC曲线、AUC值、正确率、召回率](https://www.jianshu.com/p/c61ae11cc5f6)\n",
    "7. [精确率、召回率、F1 值、ROC、AUC 各自的优缺点是什么？ - 竹间智能 Emotibot的回答 - 知乎](https://www.zhihu.com/question/30643044/answer/161955532)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
